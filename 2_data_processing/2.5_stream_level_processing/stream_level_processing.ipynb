{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream level data processing\n",
    "\n",
    "This script works exactly as the groundwater_head_processing, since the stream level in the project was obtained from a time series from a pressure transducer.\n",
    "\n",
    "Joaquim Altimiras Granel, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Obtain and merge data\n",
    "\n",
    "# Mismatches in timesteps is handled by the merge_asof function below\n",
    "\n",
    "def obtain_data():\n",
    "    \n",
    "    # Prompt user for file paths\n",
    "    p_baro_file = input(\"Enter the path of the barometric pressure file (P_baro): \")\n",
    "    p_absolute_file = input(\"Enter the path of the absolute pressure file (P_absolute) for the stream level measurements: \")\n",
    "    \n",
    "    # Read the data from the Excel files\n",
    "    # Read the files, use columns 1, 2 and 3 and assign column names\n",
    "    p_baro_data = pd.read_excel(p_baro_file, usecols=[0, 1, 2], names=['Date/time', 'P_baro', 'Quality accepted?'])\n",
    "    p_absolute_data = pd.read_excel(p_absolute_file, usecols=[0, 1, 2], names=['Date/time', 'P_absolute', 'Quality accepted?'])\n",
    "\n",
    "    # Quality control\n",
    "    # Filter out rows where 'Quality accepted?' is 'N'\n",
    "    # Checks each row if the value is Y. If it is, it saves it, otherwise not\n",
    "    p_baro_data = p_baro_data[p_baro_data['Quality accepted?'] == 'Y']\n",
    "    p_absolute_data = p_absolute_data[p_absolute_data['Quality accepted?'] == 'Y']\n",
    "    \n",
    "    # Ensure the DateTime columns are in correct format\n",
    "    # Converts the first column to datetime according to pandas\n",
    "    p_baro_data['Date/time'] = pd.to_datetime(p_baro_data['Date/time'])\n",
    "    p_absolute_data['Date/time'] = pd.to_datetime(p_absolute_data['Date/time'])\n",
    "\n",
    "    # Merge the datasets on the DateTime column with a tolerance, takes closest value if perfect match cannot be found\n",
    "    # The tolerance is very important, since some values might be removed in the filter process\n",
    "    # If the merge_asof does not find anything within the tolerance, it leaves NaN in that space, which can be seen later\n",
    "    merged_data = pd.merge_asof(p_baro_data.sort_values('Date/time'), \n",
    "                                p_absolute_data.sort_values('Date/time'), \n",
    "                                on='Date/time', \n",
    "                                tolerance=pd.Timedelta('2 hours'),\n",
    "                                direction='nearest')\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "merged_data = obtain_data()\n",
    "\n",
    "# Calculate compensated pressure and add it to the DataFrame\n",
    "merged_data['P_compensated'] = merged_data['P_absolute'] - merged_data['P_baro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to masl.\n",
    "\n",
    "# Reference level in meters above sea level at top of the well\n",
    "reference_level = float(input(\"Enter the reference level in meters above sea level: \"))\n",
    "\n",
    "# Distance from top of well to submerged transducer\n",
    "diver_distance = float(input(\"Enter the distance from top of well to submerged transducer in meters: \"))\n",
    "\n",
    "# Calculate diver level\n",
    "diver_level = reference_level - diver_distance\n",
    "\n",
    "# Recalculate compensated series to masl.\n",
    "merged_data['h_compensated'] = merged_data['P_compensated'] / 100 + diver_level\n",
    "\n",
    "\n",
    "# Visualize the results\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Compensated Water Pressure\n",
    "plt.plot(merged_data['Date/time'], merged_data['h_compensated'], label='Compensated Water level', color='blue', linestyle='-')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Groundwater Level Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Water Level (masl)')\n",
    "plt.legend()\n",
    "\n",
    "# Improve formatting of the x-axis dates\n",
    "plt.gcf().autofmt_xdate()  # Auto-format the date labels for better readability\n",
    "plt.grid(True)  # Add a grid for better readability\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample for daily averages\n",
    "\n",
    "# Create new dataframe with columns 0 and 6\n",
    "daily_avg = merged_data.iloc[:, [0, 6]].copy()\n",
    "\n",
    "# Set the date column as index\n",
    "daily_avg.set_index(daily_avg.columns[0], inplace=True)\n",
    "\n",
    "# Resample for daily average\n",
    "daily_avg = daily_avg.resample('D').mean()\n",
    "\n",
    "# Remove index setting\n",
    "daily_avg = daily_avg.reset_index()\n",
    "\n",
    "# Visualize resampeled data\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Compensated Water Pressure\n",
    "plt.plot(daily_avg['Date/time'], daily_avg['h_compensated'], label='Compensated Water level [daily]', color='blue', linestyle='-')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Groundwater Level Over Time [daily]')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Water Level (masl)')\n",
    "plt.legend()\n",
    "\n",
    "# Improve formatting of the x-axis dates\n",
    "plt.gcf().autofmt_xdate()  # Auto-format the date labels for better readability\n",
    "plt.grid(True)  # Add a grid for better readability\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data function\n",
    "\n",
    "def export_result(dataframe):\n",
    "    # Input name of original file\n",
    "    original_water_file = input(\"Enter the name of the original water pressure file (P_absolute): \")\n",
    "\n",
    "    # Let the user specify the output directory\n",
    "    #compensated_dir = input(\"Enter the directory where you want to save the file: \")\n",
    "    #if not os.path.exists(compensated_dir):\n",
    "    #    os.makedirs(compensated_dir, exist_ok=True)\n",
    "\n",
    "    # Specify the directory to save the file\n",
    "    compensated_dir = r'2_data_processing\\2.5_stream_level_processing'\n",
    "    if not os.path.exists(compensated_dir):\n",
    "        os.makedirs(compensated_dir, exist_ok=True)\n",
    "\n",
    "    # Generate the file path for the new Excel file\n",
    "    base_file_name = os.path.basename(original_water_file)\n",
    "    new_file_name = base_file_name + '_compensated_daily' + '.xlsx'\n",
    "    file_path = os.path.join(compensated_dir, new_file_name)\n",
    "\n",
    "    # Export DataFrame to Excel\n",
    "    try:\n",
    "        dataframe.to_excel(file_path, index=False)\n",
    "        print(f\"Data successfully exported to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting data: {e}\")\n",
    "\n",
    "#export_result(merged_data)\n",
    "export_result(daily_avg)\n",
    "#export_result(weekly_avg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
