{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for baseflow separation\n",
    "\n",
    "Stream flow input data needed. Converted from xlsx to csv, and then exported as xlsx.\n",
    "\n",
    "Exports file that includes both total flow and baseflow.\n",
    "\n",
    "This new file will be used in all the BFMs and TFMs.\n",
    "\n",
    "Joaquim Altimiras Granel, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import baseflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Additional data processing (transform input file to csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input data. Use xlsx-file from inputs and place the output file in the models folder. Only needed the first time.\n",
    "\n",
    "# Input file path\n",
    "file_path = input(\"Enter path for file (DAY):\")\n",
    "\n",
    "# Read file\n",
    "flow_data = pd.read_excel(file_path, usecols=[0, 1], names=[\"date_time\", \"flow\"], parse_dates=['date_time'])\n",
    "\n",
    "# Snippet the data between start and end date\n",
    "start_date = '2022-12-01'\n",
    "end_date = '2024-03-19'\n",
    "\n",
    "# Filter the data between start_date and end_date\n",
    "flow_data = flow_data.loc[(flow_data['date_time'] >= start_date) & (flow_data['date_time'] <= end_date)]\n",
    "\n",
    "# Count missing before interpolation\n",
    "missing_count_before = flow_data['flow'].isna().sum()\n",
    "\n",
    "# Interpolate missing values\n",
    "flow_data['flow'] = flow_data['flow'].interpolate()\n",
    "\n",
    "# Count missing after interpolation\n",
    "missing_count_after = flow_data['flow'].isna().sum()\n",
    "\n",
    "# Calculate the number of interpolated values\n",
    "interpolated_count = missing_count_before - missing_count_after\n",
    "\n",
    "# Print the number of interpolated values\n",
    "print(f\"Number of interpolated values: {interpolated_count}\")\n",
    "\n",
    "# Check if there are still any missing values not filled (e.g., at the beginning or end of the series)\n",
    "if missing_count_after > 0:\n",
    "    print(f\"Warning: There are {missing_count_after} missing values that were not interpolated.\")\n",
    "\n",
    "# Ask for the output directory path\n",
    "output_dir = input(\"Enter the directory path to save the file: \")\n",
    "\n",
    "# Ask for the output file name\n",
    "output_file_name = input(\"Enter the output file name (without .csv extension): \")\n",
    "\n",
    "# Ensure the file name has .csv extension\n",
    "if not output_file_name.endswith('.csv'):\n",
    "    output_file_name += '.csv'\n",
    "\n",
    "# Combine directory and file name to create full path\n",
    "output_file_path = os.path.join(output_dir, output_file_name)\n",
    "\n",
    "# Save the data in a csv file at the specified location\n",
    "flow_data.to_csv(output_file_path, index=False, sep=',', float_format='%.6f')\n",
    "\n",
    "# Confirmation\n",
    "print(f\"Data exported successfully to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Baseflow separation procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize input data\n",
    "\n",
    "input_file = input(\"Enter path for input file:\")\n",
    "\n",
    "data = pd.read_csv(input_file, parse_dates=['date_time'], index_col='date_time')\n",
    "\n",
    "# Snippet the data between start and end date\n",
    "start_date = '2022-12-01'\n",
    "end_date = '2024-03-19'\n",
    "\n",
    "# Filter the data between start_date and end_date\n",
    "data2 = data.loc[start_date:end_date]\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify it's loaded correctly\n",
    "print(data.head())\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(data.index, data['flow'], label='Data', color='blue', linewidth=2)\n",
    "plt.title('Data Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Data Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT - Remove yearly filter from a specific function (clean_streamflow) in the package\n",
    "\n",
    "import baseflow.utils\n",
    "\n",
    "def custom_clean_streamflow(date, Q):\n",
    "    has_value = np.isfinite(Q)\n",
    "    Q = np.abs(Q[has_value])\n",
    "    date = date[has_value]\n",
    "    return Q, date\n",
    "\n",
    "# Override the original clean_streamflow with your custom function\n",
    "baseflow.utils.clean_streamflow = custom_clean_streamflow\n",
    "\n",
    "import baseflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseflow separation\n",
    "\n",
    "input_file = input(\"Enter path for input file:\")\n",
    "Q, date = baseflow.load_streamflow(input_file)\n",
    "\n",
    "b, KGEs = baseflow.separation(Q, date, area=9947129) # Catchment area in m^2\n",
    "\n",
    "best_method_name = b.dtype.names[KGEs.argmax()]\n",
    "best_baseflow_series = b[best_method_name]\n",
    "\n",
    "print(f'Best Method: {b.dtype.names[KGEs.argmax()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIAL: Visualize all methods\n",
    "\n",
    "# Baseflow separation\n",
    "\n",
    "input_file = input(\"Enter path for input file:\")\n",
    "Q, date = baseflow.load_streamflow(input_file)\n",
    "\n",
    "# Convert structured date array to pandas datetime series\n",
    "date = pd.to_datetime({'year': date['Y'], 'month': date['M'], 'day': date['D']})\n",
    "\n",
    "# Perform baseflow separation\n",
    "b, KGEs = baseflow.separation(Q, date, area=9947129)  # Catchment area in m^2\n",
    "\n",
    "# Plotting all baseflow separation methods and their KGE values\n",
    "fig, axs = plt.subplots(len(b.dtype.names), 1, figsize=(10, 5*len(b.dtype.names)))  # Adjust size as necessary\n",
    "\n",
    "for i, method in enumerate(b.dtype.names):\n",
    "    axs[i].plot(date, Q, label='Total Flow', color='blue', alpha=0.6)\n",
    "    axs[i].plot(date, b[method], label='Baseflow - ' + method, color='green')\n",
    "    axs[i].set_title(f'{method} - KGE: {KGEs[i]:.3f}')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Automatically adjust the plot layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Finding and printing the best method based on KGE\n",
    "best_method_index = KGEs.argmax()\n",
    "best_method_name = b.dtype.names[best_method_index]\n",
    "best_baseflow_series = b[best_method_name]\n",
    "\n",
    "print(f'Best Method: {best_method_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See all methods\n",
    "\n",
    "import baseflow.methods\n",
    "import pkgutil\n",
    "\n",
    "# This will list all modules under the baseflow.methods package\n",
    "available_methods = [name for _, name, _ in pkgutil.iter_modules(baseflow.methods.__path__)]\n",
    "\n",
    "print(\"Available baseflow separation methods:\")\n",
    "for method in available_methods:\n",
    "    print(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the results\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import baseflow.methods\n",
    "import pkgutil\n",
    "\n",
    "# Ensure 'available_methods' is defined. This would typically be a list of methods from baseflow.methods.\n",
    "available_methods = [method.name for method in pkgutil.iter_modules(baseflow.methods.__path__)]\n",
    "\n",
    "# User selects the method\n",
    "selected_method = input(\"Enter the name of the method you want to export: \")\n",
    "\n",
    "# Validate user selection\n",
    "if selected_method not in available_methods:\n",
    "    raise ValueError(f\"Selected method {selected_method} is not available.\")\n",
    "\n",
    "# Assuming `date` is already in the correct format\n",
    "# Convert structured date array to pandas datetime series\n",
    "if isinstance(date, pd.DatetimeIndex):\n",
    "    date_datetime = date\n",
    "else:\n",
    "    date_datetime = pd.to_datetime(date)\n",
    "\n",
    "# Create a DataFrame using the selected method\n",
    "df = pd.DataFrame({\n",
    "    'Date': date_datetime,\n",
    "    'Total Streamflow': Q,\n",
    "    f'Baseflow ({selected_method})': b[selected_method]\n",
    "})\n",
    "\n",
    "# Get the output directory and file name from the user\n",
    "output_dir = input(\"Enter the directory path to save the file: \")\n",
    "file_name = input(\"Enter the name for the output Excel file (without extension): \")\n",
    "\n",
    "# Ensure the file name has .xlsx extension\n",
    "if not file_name.endswith('.xlsx'):\n",
    "    file_name += '.xlsx'\n",
    "\n",
    "# Combine directory and file name to create full path\n",
    "output_file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f'File saved successfully at {output_file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
